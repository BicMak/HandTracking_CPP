
/**
 * @file Mouse_event.h
 * @brief Hand gesture-based mouse control system
 *
 * =============================================================================
 * ğŸ”§ TODO: í´ë¦­/ë“œë˜ê·¸ ë¶„ê¸° ì‹œì  ë³€ê²½ ì‘ì—… (ëˆ„ë¥¼ ë•Œ ë¶„ê¸°ë¡œ ìˆ˜ì •)
 * =============================================================================
 *
 * í˜„ì¬ ìƒíƒœ: ë—„ ë•Œ ë¶„ê¸° ë°©ì‹ (mouse_leftoffì—ì„œ í´ë¦­/ë“œë˜ê·¸ íŒë‹¨)
 * ëª©í‘œ ìƒíƒœ: ëˆ„ë¥¼ ë•Œ ë¶„ê¸° ë°©ì‹ (mouse_leftonì—ì„œ ì¦‰ì‹œ íŒë‹¨)
 *
 * ğŸ“‹ ìˆ˜ì •í•´ì•¼ í•  í•¨ìˆ˜ë“¤:
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ 1. mouse_lefton()  - ë©”ì¸ ìˆ˜ì • ëŒ€ìƒ                                â”‚
 * â”‚    â€¢ predict_user_intent() í•¨ìˆ˜ êµ¬í˜„ í•„ìš”                          â”‚
 * â”‚    â€¢ í´ë¦­ ì˜ˆì¸¡ì‹œ: LEFTDOWN+LEFTUP ë™ì‹œ ì‹¤í–‰                        â”‚
 * â”‚    â€¢ ë“œë˜ê·¸ ì˜ˆì¸¡ì‹œ: LEFTDOWNë§Œ ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)               â”‚
 * â”‚                                                                     â”‚
 * â”‚ 2. mouse_leftoff() - ë‹¨ìˆœí™” í•„ìš”                                   â”‚
 * â”‚    â€¢ ë“œë˜ê·¸ ì™„ë£Œë§Œ ì²˜ë¦¬ (í´ë¦­ì€ leftonì—ì„œ ì´ë¯¸ ì™„ë£Œë¨)            â”‚
 * â”‚    â€¢ left_click_flag ì²´í¬ í›„ LEFTUPë§Œ ì‹¤í–‰                         â”‚
 * â”‚                                                                     â”‚
 * â”‚ 3. predict_user_intent() - ìƒˆë¡œ êµ¬í˜„ í•„ìš”                          â”‚
 * â”‚    â€¢ ì† ì•ˆì •ì„±, ì›€ì§ì„ ì†ë„ ë¶„ì„                                   â”‚
 * â”‚    â€¢ CLICK_INTENT vs DRAG_INTENT ë°˜í™˜                              â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * ğŸ¯ ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜ ì•„ì´ë””ì–´:
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ â€¢ ì† ì•ˆì •ì„±: hand_normal_loc ì¢Œí‘œ ë³€í™”ëŸ‰ ë¶„ì„                      â”‚
 * â”‚ â€¢ ì›€ì§ì„ ì†ë„: ì´ì „ í”„ë ˆì„ê³¼ì˜ ìœ„ì¹˜ ì°¨ì´                           â”‚
 * â”‚ â€¢ ì œìŠ¤ì²˜ ì§€ì†ì‹œê°„: ì–¼ë§ˆë‚˜ ë¹¨ë¦¬ ë“¤ì–´ì™”ëŠ”ì§€                          â”‚
 * â”‚ â€¢ ì„ê³„ê°’: ì•ˆì •ì ì´ê³  ë¹ ë¥´ë©´ í´ë¦­, ì•„ë‹ˆë©´ ë“œë˜ê·¸                    â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * âš ï¸  ì£¼ì˜ì‚¬í•­:
 * â€¢ ì˜ˆì¸¡ ì‹¤íŒ¨ì‹œ ì˜ë„ì™€ ë‹¤ë¥¸ ë™ì‘ ë°œìƒ (í´ë¦­ì¸ë° ë“œë˜ê·¸, ë“œë˜ê·¸ì¸ë° í´ë¦­)
 * â€¢ ì• ë§¤í•˜ë©´ DRAG_INTENTë¡œ ê¸°ë³¸ ì„¤ì • (ë” ì•ˆì „í•¨)
 * â€¢ ë””ë²„ê¹…ìš© ì¶œë ¥ë¬¸ìœ¼ë¡œ ì˜ˆì¸¡ ì •í™•ë„ ëª¨ë‹ˆí„°ë§ í•„ìš”
 *
 * ğŸ“Š ê¸°ëŒ€ íš¨ê³¼:
 * â€¢ í´ë¦­ ë°˜ì‘ì†ë„ í–¥ìƒ (ì¦‰ì‹œ ì™„ë£Œ)
 * â€¢ ì‚¬ìš©ì ê²½í—˜ ê°œì„  (ë¹ ë¥¸ í”¼ë“œë°±)
 * â€¢ ì½”ë“œ ë³µì¡ë„ ì¦ê°€ (ì˜ˆì¸¡ ë¡œì§ ì¶”ê°€)
 *
 * =============================================================================
 */

#pragma once

#include <windows.h>
#include <string.h>
#include <iostream>
#include <ctime>
#include <onnxruntime_cxx_api.h>
#include <opencv2/opencv.hpp>

#include "OnnxModel.h"
#include "OnnxYolo.h"

using TimePoint = std::chrono::high_resolution_clock::time_point;

/**
 * @brief To save vector of point
 *
 * @details
 * - vec : normalize hand result vector(x,y)
 */
struct normal_point_locset {
    cv::Vec2f vec;
};

class Mouse_event {
private:
    //screen infomation
    int screen_width;
    int screen_height;
    cv::Mat img;
    
    //vector point variable
    std::vector<normal_point_locset> hand_normal_loc;
    int hand_id;
    float hand_score;
    POINT cursorPos;
    std::vector<double> tip_dist;
    cv::Vec2f yolo_pivot;
    cv::Vec2f fingertip_pivot;

    cv::Vec2f bbox_curpose;
    cv::Vec2f starting_point;

    //event code
    std::string envet_code;
    cv::Vec2f current_pos;
    bool left_click_flag;
    TimePoint start_time = std::chrono::high_resolution_clock::now();;

    //curser Moving parameter
    float DEAD_ZONE = 3.0f;
    float ALPHA = 0.25f;
    float smooth_x = -1, smooth_y = -1;
    int center_x;
    int center_y;
    int cursor_x = 0;
    int cursor_y = 0;

public:
    Mouse_event() {
        GetCursorPos(&cursorPos);
        screen_width = GetSystemMetrics(SM_CXSCREEN);
        screen_height = GetSystemMetrics(SM_CYSCREEN);
        center_x = screen_width / 2;
        center_y = screen_height / 2;
    }

    /**
     * @brief Update hand position data from ONNX prediction results
     *
     * Processes MediaPipe hand landmark predictions and YOLO hand detection results:
     * 1. Extracts and stores YOLO bounding box center coordinates and hand class ID
     * 2. Normalizes MediaPipe joint coordinates (21 landmarks) with horizontal flip
     *    - Coordinates are normalized to [0,1] range from 224x224 input
     *    - X coordinates are horizontally flipped (1 - x/224)
     *
     * @param onnx_data MediaPipe prediction tensor containing 63 values (21 landmarks Ã— 3)
     * @param onnx_yolodata HAGRID YOLO10s detection result with bbox and classification
     */
    void updatehandpos(Onnx_Outputs onnx_data,
                       Detection onnx_yolodata) {
        normal_point_locset temp;

        hand_normal_loc.clear();

        hand_score = onnx_yolodata.confidence;
        hand_id = onnx_yolodata.class_id;
        bbox_curpose[0] = (1-onnx_yolodata.x/640.0f);
        bbox_curpose[1] = onnx_yolodata.y / 640.0f;
        std::cout << bbox_curpose[0] << std::endl;
        std::cout << bbox_curpose[1] << std::endl;

        // Normalize Point coordinates
        for (int i = 0; i < 21; i++) {
            int idx1 = 3 * i;
            int idx2 = 3 * i + 1;
            temp.vec =  cv::Vec2f((1 - onnx_data.landmarks[idx1] / 224),
                                  (onnx_data.landmarks[idx2] / 224) );
            hand_normal_loc.push_back(temp);
        }
    }


    /**
     * @brief Update hand position data from ONNX prediction results
     *
     * Processes MediaPipe hand landmark predictions and YOLO hand detection results:
     * 1. Extracts and stores YOLO bounding box center coordinates and hand class ID
     *    - Yolo coordinates normalized to [0,1] range from 640x640 input
     *    - Yolo X coordinates are horizontally flipped (1 - x/640)
     * 2. Normalizes MediaPipe joint coordinates (21 landmarks) with horizontal flip
     *    - Coordinates are normalized to [0,1] range from 224x224 input
     *    - X coordinates are horizontally flipped (1 - x/224)
     *
     * @param onnx_data MediaPipe prediction tensor containing 63 values (21 landmarks Ã— 3)
     * @param onnx_yolodata HAGRID YOLO10s detection result with bbox and classification
     */
    void mouse_moving() {
        
        int scailer = 2;
        float offset_x = (hand_normal_loc[8].vec[0] - 0.5f) * scailer * screen_width;
        float offset_y = (hand_normal_loc[8].vec[1] - 0.5f) * scailer * screen_height;
        float raw_x = center_x + offset_x;
        float raw_y = center_y + offset_y;

        // ğŸ”§ ë“œë˜ê·¸ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ YOLO ê¸°ì¤€ì  ì—…ë°ì´íŠ¸
        if (smooth_x < 0) {
            smooth_x = raw_x;
            smooth_y = raw_y;
            cursor_x = (int)raw_x;
            cursor_y = (int)raw_y;

            // ğŸ”§ fingertip_pivotë„ ë“œë˜ê·¸ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ ì—…ë°ì´íŠ¸
            if (!left_click_flag) {
                fingertip_pivot = cv::Vec2f(hand_normal_loc[8].vec[0], hand_normal_loc[8].vec[1]);
            }

            SetCursorPos(cursor_x, cursor_y);
        }
        else {
            smooth_x = smooth_x * (1.0f - ALPHA) + raw_x * ALPHA;
            smooth_y = smooth_y * (1.0f - ALPHA) + raw_y * ALPHA;

            float dx = smooth_x - cursor_x;
            float dy = smooth_y - cursor_y;

            float distance = sqrt(dx * dx + dy * dy);

            if (distance > DEAD_ZONE) {
                cursor_x = (int)smooth_x;
                cursor_y = (int)smooth_y;

                // ğŸ”§ fingertip_pivotë„ ë“œë˜ê·¸ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ ì—…ë°ì´íŠ¸
                if (!left_click_flag) {
                    fingertip_pivot = cv::Vec2f(hand_normal_loc[8].vec[0], hand_normal_loc[8].vec[1]);
                }

                SetCursorPos(cursor_x, cursor_y);
            }

        }
    }


    /**
     * @brief Control left mouse press with time-based click/drag classification
     *
     * Determines user intent based on gesture duration and executes accordingly:
     *
     * **Click Classification** (automatic completion):
     * - Detects brief gestures (< 0.5s duration)
     * - Automatically sends MOUSEEVENTF_LEFTUP in mouse_leftoff()
     * - Completes interaction when gesture is released quickly
     *
     * **Drag Classification** (progressive operation):
     * - Identifies sustained press gestures (â‰¥ 0.5s duration)
     * - Enables continuous cursor tracking based on YOLO bbox center
     * - Maintains drag state until corresponding mouse_leftoff() call
     * - Updates cursor position in real-time during drag progression
     *
     * **Classification Logic**:
     * - Initial gesture: Always sends MOUSEEVENTF_LEFTDOWN
     * - After 500ms: Activates drag mode with cursor tracking with yolo bbox center pos
     * - Cursor follows hand movement using absolute positioning
     *
     * @note This approach uses time-based classification for simplicity
     * @warning 500ms delay before drag activation may feel slightly sluggish
     * @see mouse_leftoff() for drag completion and click finalization
     */
    void mouse_lefton() {
        float scailer = 1.5;
        auto current_time = std::chrono::high_resolution_clock::now();
        
        if (left_click_flag == FALSE) {
            left_click_flag = TRUE;
            starting_point = fingertip_pivot;  // í™”ë©´ í”½ì…€ ì¢Œí‘œë¡œ ì €ì¥ë¨
            start_time = std::chrono::high_resolution_clock::now();

            yolo_pivot = bbox_curpose;
            mouse_event(MOUSEEVENTF_LEFTDOWN, 0, 0, 0, 0);
        }
        else if (left_click_flag == TRUE) {
            auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(
                current_time - start_time
            ).count();

            if (duration >= 500) {
                // ğŸ”§ YOLO ë°”ìš´ë”©ë°•ìŠ¤ ì„¼í„° ê¸°ë°˜ ì ˆëŒ€ì¢Œí‘œ ê³„ì‚°
                float offset_x = (bbox_curpose[0] - 0.5f) * scailer * screen_width;
                float offset_y = (bbox_curpose[1] - 0.5f) * scailer * screen_height;

                float raw_x = center_x + offset_x;
                float raw_y = center_y + offset_y;

                // ì§ì ‘ ì»¤ì„œ ì´ë™ 
                cursor_x = (int)raw_x;
                cursor_y = (int)raw_y;
                SetCursorPos(cursor_x, cursor_y);
            }
        }
    }

    /**
     * @brief Complete mouse operations (both click and drag)
     *
     * Handles final LEFTUP event for all mouse interactions:
     *
     * **Click Completion**:
     * - Sends MOUSEEVENTF_LEFTUP for brief gestures (< 0.5s)
     * - Completes click operation that started in mouse_lefton()
     * - Quick tap gestures result in standard click behavior
     *
     * **Drag Completion**:
     * - Sends MOUSEEVENTF_LEFTUP to finalize drag-and-drop operation
     * - Completes drag operation after sustained gesture (â‰¥ 0.5s)
     * - Resets drag tracking flags and clears temporary state
     *
     * **Common Functionality**:
     * - Always resets left_click_flag to FALSE
     * - Provides operation completion feedback
     * - Safely handles calls when no active operation exists
     *
     * @note This function handles LEFTUP for both clicks and drags
     * @see mouse_lefton() for operation initiation and drag tracking
     */
    void mouse_leftoff() {
        if (left_click_flag) {
            left_click_flag = FALSE;
            mouse_event(MOUSEEVENTF_LEFTUP, 0, 0, 0, 0);
            std::cout << "ğŸ–±ï¸ ë“œë˜ê·¸ ì¢…ë£Œ" << std::endl;
        }

    }


    /**
    * @brief Process hand gesture recognition and execute corresponding mouse actions
    *
    * Main processing pipeline that interprets YOLO hand detection results and
    * triggers appropriate mouse control functions based on gesture classification:
    *
    * **Gesture-to-Action Mapping**:
    * - Class 11/19 (Pointing): Cursor movement via mouse_moving()
    * - Class 14 (Fist): Mouse press/drag initiation via mouse_lefton()
    * - Class 20 (Open Palm): Mouse release/operation completion via mouse_leftoff()
    *
    * **Quality Control**:
    * - Minimum confidence threshold: 0.4 (40%)
    * - Low confidence gestures are ignored to prevent false triggers
    * - Active drag operations are safely terminated if hand detection fails
    *
    * **Safety Features**:
    * - Automatic drag termination on detection loss
    * - Prevents stuck drag states from unstable hand tracking
    * - Graceful degradation when hand visibility is poor
    *
    * @note This function should be called once per frame in the main loop
    * @warning Confidence threshold (0.4) may need adjustment based on lighting conditions
    * @see mouse_moving(), mouse_lefton(), mouse_leftoff() for individual gesture handlers
    */
    void process() {
        if (hand_score > 0.4) {
            switch (hand_id) {
            case 11:  // Pointing - ë§ˆìš°ìŠ¤ ì´ë™
                mouse_moving();
                break;
            case 19:  // Pointing - ë§ˆìš°ìŠ¤ ì´ë™
                mouse_moving();
                break;
            case 14:  // Fist - ë“œë˜ê·¸
                mouse_lefton();
                break;
            case 20:  // Open Palm - ë“œë˜ê·¸ ì¢…ë£Œ
                mouse_leftoff();
                break;
            default:
                break;
            }
        }
        else {
            if (left_click_flag) {
                std::cout << "âš ï¸ ì† ì¸ì‹ ë¶ˆì•ˆì •ìœ¼ë¡œ ë“œë˜ê·¸ ê°•ì œ ì¢…ë£Œ" << std::endl;
                mouse_leftoff();
            }
        }
    }

};



/**
 * @file Mouse_event.h
 * @brief Hand gesture-based mouse control system
 *
 * =============================================================================
 * ğŸ”§ TODO: í´ë¦­/ë“œë˜ê·¸ ë¶„ê¸° ì‹œì  ë³€ê²½ ì‘ì—… (ëˆ„ë¥¼ ë•Œ ë¶„ê¸°ë¡œ ìˆ˜ì •)
 * =============================================================================
 *
 * í˜„ì¬ ìƒíƒœ: ë—„ ë•Œ ë¶„ê¸° ë°©ì‹ (mouse_leftoffì—ì„œ í´ë¦­/ë“œë˜ê·¸ íŒë‹¨)
 * ëª©í‘œ ìƒíƒœ: ëˆ„ë¥¼ ë•Œ ë¶„ê¸° ë°©ì‹ (mouse_leftonì—ì„œ ì¦‰ì‹œ íŒë‹¨)
 *
 * ğŸ“‹ ìˆ˜ì •í•´ì•¼ í•  í•¨ìˆ˜ë“¤:
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ 1. mouse_lefton()  - ë©”ì¸ ìˆ˜ì • ëŒ€ìƒ                                â”‚
 * â”‚    â€¢ predict_user_intent() í•¨ìˆ˜ êµ¬í˜„ í•„ìš”                          â”‚
 * â”‚    â€¢ í´ë¦­ ì˜ˆì¸¡ì‹œ: LEFTDOWN+LEFTUP ë™ì‹œ ì‹¤í–‰                        â”‚
 * â”‚    â€¢ ë“œë˜ê·¸ ì˜ˆì¸¡ì‹œ: LEFTDOWNë§Œ ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)               â”‚
 * â”‚                                                                     â”‚
 * â”‚ 2. mouse_leftoff() - ë‹¨ìˆœí™” í•„ìš”                                   â”‚
 * â”‚    â€¢ ë“œë˜ê·¸ ì™„ë£Œë§Œ ì²˜ë¦¬ (í´ë¦­ì€ leftonì—ì„œ ì´ë¯¸ ì™„ë£Œë¨)            â”‚
 * â”‚    â€¢ left_click_flag ì²´í¬ í›„ LEFTUPë§Œ ì‹¤í–‰                         â”‚
 * â”‚                                                                     â”‚
 * â”‚ 3. predict_user_intent() - ìƒˆë¡œ êµ¬í˜„ í•„ìš”                          â”‚
 * â”‚    â€¢ ì† ì•ˆì •ì„±, ì›€ì§ì„ ì†ë„ ë¶„ì„                                   â”‚
 * â”‚    â€¢ CLICK_INTENT vs DRAG_INTENT ë°˜í™˜                              â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * ğŸ¯ ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜ ì•„ì´ë””ì–´:
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ â€¢ ì† ì•ˆì •ì„±: hand_normal_loc ì¢Œí‘œ ë³€í™”ëŸ‰ ë¶„ì„                      â”‚
 * â”‚ â€¢ ì›€ì§ì„ ì†ë„: ì´ì „ í”„ë ˆì„ê³¼ì˜ ìœ„ì¹˜ ì°¨ì´                           â”‚
 * â”‚ â€¢ ì œìŠ¤ì²˜ ì§€ì†ì‹œê°„: ì–¼ë§ˆë‚˜ ë¹¨ë¦¬ ë“¤ì–´ì™”ëŠ”ì§€                          â”‚
 * â”‚ â€¢ ì„ê³„ê°’: ì•ˆì •ì ì´ê³  ë¹ ë¥´ë©´ í´ë¦­, ì•„ë‹ˆë©´ ë“œë˜ê·¸                    â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * âš ï¸  ì£¼ì˜ì‚¬í•­:
 * â€¢ ì˜ˆì¸¡ ì‹¤íŒ¨ì‹œ ì˜ë„ì™€ ë‹¤ë¥¸ ë™ì‘ ë°œìƒ (í´ë¦­ì¸ë° ë“œë˜ê·¸, ë“œë˜ê·¸ì¸ë° í´ë¦­)
 * â€¢ ì• ë§¤í•˜ë©´ DRAG_INTENTë¡œ ê¸°ë³¸ ì„¤ì • (ë” ì•ˆì „í•¨)
 * â€¢ ë””ë²„ê¹…ìš© ì¶œë ¥ë¬¸ìœ¼ë¡œ ì˜ˆì¸¡ ì •í™•ë„ ëª¨ë‹ˆí„°ë§ í•„ìš”
 *
 * ğŸ“Š ê¸°ëŒ€ íš¨ê³¼:
 * â€¢ í´ë¦­ ë°˜ì‘ì†ë„ í–¥ìƒ (ì¦‰ì‹œ ì™„ë£Œ)
 * â€¢ ì‚¬ìš©ì ê²½í—˜ ê°œì„  (ë¹ ë¥¸ í”¼ë“œë°±)
 * â€¢ ì½”ë“œ ë³µì¡ë„ ì¦ê°€ (ì˜ˆì¸¡ ë¡œì§ ì¶”ê°€)
 *
 * =============================================================================
 */

#pragma once

#include <windows.h>
#include <string.h>
#include <iostream>
#include <onnxruntime_cxx_api.h>
#include <opencv2/opencv.hpp>

#include "OnnxModel.h"
#include "OnnxYolo.h"


/**
 * @brief To save vector of point
 *
 * @details
 * - vec : normalize hand result vector(x,y)
 */
struct normal_point_locset {
    cv::Vec2f vec;
};

class Mouse_event {
private:
    //screen infomation
    int screen_width;
    int screen_height;
    cv::Mat img;
    
    //vector point variable
    std::vector<normal_point_locset> hand_normal_loc;
    int hand_id;
    float hand_score;
    POINT cursorPos;
    std::vector<double> tip_dist;
    cv::Vec2f yolo_pivot;
    cv::Vec2f fingertip_pivot;
    cv::Vec2f bbox_curpose;
    cv::Vec2f starting_point;

    //event code
    std::string envet_code;
    cv::Vec2f current_pos;
    bool left_click_flag;
    double fist_start_time;

    //curser Moving parameter
    float DEAD_ZONE = 3.0f;
    float ALPHA = 0.25f;
    float smooth_x = -1, smooth_y = -1;
    int center_x;
    int center_y;
    int cursor_x = 0;
    int cursor_y = 0;

public:
    Mouse_event() {
        GetCursorPos(&cursorPos);
        screen_width = GetSystemMetrics(SM_CXSCREEN);
        screen_height = GetSystemMetrics(SM_CYSCREEN);
        center_x = screen_width / 2;
        center_y = screen_height / 2;
    }

    /**
     * @brief Update hand position data from ONNX prediction results
     *
     * Processes MediaPipe hand landmark predictions and YOLO hand detection results:
     * 1. Extracts and stores YOLO bounding box center coordinates and hand class ID
     * 2. Normalizes MediaPipe joint coordinates (21 landmarks) with horizontal flip
     *    - Coordinates are normalized to [0,1] range from 224x224 input
     *    - X coordinates are horizontally flipped (1 - x/224)
     *
     * @param onnx_data MediaPipe prediction tensor containing 63 values (21 landmarks Ã— 3)
     * @param onnx_yolodata HAGRID YOLO10s detection result with bbox and classification
     */
    void updatehandpos(Onnx_Outputs onnx_data,
                       Detection onnx_yolodata) {
        normal_point_locset temp;

        hand_normal_loc.clear();

        hand_score = onnx_yolodata.confidence;
        hand_id = onnx_yolodata.class_id;
        bbox_curpose[0] = onnx_yolodata.x;
        bbox_curpose[1] = onnx_yolodata.y;

        // Normalize Point coordinates
        for (int i = 0; i < 21; i++) {
            int idx1 = 3 * i;
            int idx2 = 3 * i + 1;
            temp.vec =  cv::Vec2f((1 - onnx_data.landmarks[idx1] / 224),
                                  (onnx_data.landmarks[idx2] / 224) );
            hand_normal_loc.push_back(temp);
        }
    }


    /**
     * @brief Update hand position data from ONNX prediction results
     *
     * Processes MediaPipe hand landmark predictions and YOLO hand detection results:
     * 1. Extracts and stores YOLO bounding box center coordinates and hand class ID
     * 2. Normalizes MediaPipe joint coordinates (21 landmarks) with horizontal flip
     *    - Coordinates are normalized to [0,1] range from 224x224 input
     *    - X coordinates are horizontally flipped (1 - x/224)
     *
     * @param onnx_data MediaPipe prediction tensor containing 63 values (21 landmarks Ã— 3)
     * @param onnx_yolodata HAGRID YOLO10s detection result with bbox and classification
     */
    void mouse_moving() {
        
        float offset_x = (hand_normal_loc[8].vec[0] - 0.5f) * 2 * screen_width;
        float offset_y = (hand_normal_loc[8].vec[1] - 0.5f) * 2 * screen_height;
        float raw_x = center_x + offset_x;
        float raw_y = center_y + offset_y;

        // ğŸ”§ ë“œë˜ê·¸ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ YOLO ê¸°ì¤€ì  ì—…ë°ì´íŠ¸
        if (smooth_x < 0) {
            smooth_x = raw_x;
            smooth_y = raw_y;
            cursor_x = (int)raw_x;
            cursor_y = (int)raw_y;

            // ğŸ”§ fingertip_pivotë„ ë“œë˜ê·¸ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ ì—…ë°ì´íŠ¸
            if (!left_click_flag) {
                fingertip_pivot = cv::Vec2f(cursor_x, cursor_y);
            }

            SetCursorPos(cursor_x, cursor_y);
        }
        else {
            smooth_x = smooth_x * (1.0f - ALPHA) + raw_x * ALPHA;
            smooth_y = smooth_y * (1.0f - ALPHA) + raw_y * ALPHA;

            float dx = smooth_x - cursor_x;
            float dy = smooth_y - cursor_y;

            float distance = sqrt(dx * dx + dy * dy);

            if (distance > DEAD_ZONE) {
                cursor_x = (int)smooth_x;
                cursor_y = (int)smooth_y;

                // ğŸ”§ fingertip_pivotë„ ë“œë˜ê·¸ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ ì—…ë°ì´íŠ¸
                if (!left_click_flag) {
                    fingertip_pivot = cv::Vec2f(cursor_x, cursor_y);
                }

                SetCursorPos(cursor_x, cursor_y);
            }

        }
    }


    /**
     * @brief Control left mouse press with immediate click/drag classification
     *
     * Determines user intent at the moment of gesture initiation and executes accordingly:
     *
     * **Click Classification** (immediate completion):
     * - Detects rapid tap gestures based on hand movement patterns
     * - Sends both MOUSEEVENTF_LEFTDOWN and MOUSEEVENTF_LEFTUP in single call
     * - Completes interaction without requiring separate release gesture
     *
     * **Drag Classification** (progressive operation):
     * - Identifies sustained press gestures for drag-and-drop operations
     * - Sends only MOUSEEVENTF_LEFTDOWN to begin drag state
     * - Maintains drag tracking until corresponding mouse_leftoff() call
     * - Updates cursor position continuously during drag progression
     *
     * **Classification Criteria**:
     * - Hand stability: Low jitter indicates click intent
     * - Gesture velocity: Quick in-out motion suggests tap
     * - Movement prediction: Extrapolated trajectory analysis
     * - Historical pattern: User behavior learning (optional)
     *
     * @note This approach prioritizes response speed over accuracy
     * @warning Misclassification may result in unintended actions
     * @see mouse_leftoff() for drag completion handling
     */
    void mouse_lefton() {
        if (left_click_flag == FALSE) {
            left_click_flag = TRUE;
            starting_point = fingertip_pivot;  // í™”ë©´ í”½ì…€ ì¢Œí‘œë¡œ ì €ì¥ë¨
            yolo_pivot = bbox_curpose;
            mouse_event(MOUSEEVENTF_LEFTDOWN, 0, 0, 0, 0);
        }
        else {
            cv::Vec2f yolo_offset;
            yolo_offset[0] = (bbox_curpose[0] - yolo_pivot[0]) * screen_width;
            yolo_offset[1] = (bbox_curpose[1] - yolo_pivot[1]) * screen_height;
            cv::Vec2f final_pos = starting_point + yolo_offset;
            SetCursorPos((int)final_pos[0], (int)final_pos[1]);
        }
    }

    /**
     * @brief Complete drag operation for sustained press gestures
     *
     * Handles drag completion only - click operations are completed in mouse_lefton():
     *
     * **Drag Completion**:
     * - Sends MOUSEEVENTF_LEFTUP to finalize drag-and-drop operation
     * - Resets drag tracking flags and clears temporary state
     * - Provides drag operation feedback to user
     *
     * **Click Handling**:
     * - No action taken for click gestures (already completed)
     * - Safely ignores calls when no active drag operation exists
     *
     * @note Only processes drag operations - clicks are handled entirely in mouse_lefton()
     * @see mouse_lefton() for click handling and drag initiation
     */
    void mouse_leftoff() {
        if (left_click_flag) {
            left_click_flag = FALSE;
            mouse_event(MOUSEEVENTF_LEFTUP, 0, 0, 0, 0);

            // ğŸ”§ ë””ë²„ê¹… ì¶œë ¥ (ì˜µì…˜)
            std::cout << "ğŸ–±ï¸ ë“œë˜ê·¸ ì¢…ë£Œ" << std::endl;
        }
        // else êµ¬ë¬¸ê³¼ return ì œê±° - ë¶ˆí•„ìš”í•¨
    }


    /**
    * @brief processing the mouse action
    *
    * if yolo hand detection class score is higher than threshold.
    * then control the mouse
    *
    */
    void process() {
        if (hand_score > 0.4) {
            switch (hand_id) {
            case 11:  // Pointing - ë§ˆìš°ìŠ¤ ì´ë™
                mouse_moving();
                break;
            case 19:  // Pointing - ë§ˆìš°ìŠ¤ ì´ë™
                mouse_moving();
                break;
            case 14:  // Fist - ë“œë˜ê·¸
                mouse_lefton();
                break;
            case 20:  // Open Palm - ë“œë˜ê·¸ ì¢…ë£Œ
                mouse_leftoff();
                break;
            default:
                break;
            }
        }
        else {
            if (left_click_flag) {
                std::cout << "âš ï¸ ì† ì¸ì‹ ë¶ˆì•ˆì •ìœ¼ë¡œ ë“œë˜ê·¸ ê°•ì œ ì¢…ë£Œ" << std::endl;
                mouse_leftoff();
            }
        }
    }

};

